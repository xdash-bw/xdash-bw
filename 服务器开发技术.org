#+title: 服务器开发技术

创建时间：2022.6.25

描述：服务器开发根本不是什么 web 框架，什么业务代码，什么管理系统。而是体系结构，操作系统，网络，分布式，数据库原理，编译原理，数据结构，调试能力等等等等等。更重要的是，这里不是 PPT Fucker 和背题家的地盘，光说没用，写两行代码立马知深浅。所以还要深厚的工程学实战能力，是真正考验计算机素养的地方。谨记！！！

- Update
  - 添加 - 聚类算法 (22.6.28 23.49)
  - 完善 - 关联挖掘：添加事务库定义，添加强关联规则：把计算可置信度和支持度移动到这：添加 Apriori 算法（从事务库中组合不同的项形成项集） (22.6.28 18.33)
  - 完善 - 关联挖掘 (22.6.28 17.58)
  - 添加 - 关联挖掘 (22.6.28 17.48)



* 服务端开发

** Web 后端 (接入层)
https://zhuanlan.zhihu.com/p/29028054

*** 简介
  + 用户交互
    填充数据，Json,XML

  + Http 协议
    跑 http 文本协议，而不是更高性能的二进制

  + 后端最前面的部分，一般带个 web. 又叫接入层
    包括 http 服务器和 web 框架

  例如 web 的各种框架，都是关注与如何与前端进行交互（往 html 里面塞入数据，解析用户字符串等）
  附带封装了访问数据库的方法，让学生可以直接通过这些个框架加调用下 nginx 命令实现

    1. 简单的请求
    2. 直接取数据库
    3. 返回页面

    的简单作业，基本就是命令行程序讨个 web 的壳，不会有大量繁重的业务。

*** Http 服务器
nginx, apache

*** 网关
**** cgi
**** servlet (java)
**** wcgi

*** Web 应用服务器
django, flask 就是使用了 wcgi 封装的 web 框架

*** restful

** 大后端
*** 简介
用户的请求接入后，路由到公司内部分布式的具体业务组件上 这里才是真正的真正的大后端，解决真正的业务需求。与 web 无关。

一般对于本科学生来说，写个后端都不会涉及到多复杂的逻辑，只要会 web 后端的知识写个 xxoo 管理系统那就差不多了。

但是，对于真正的工业级产品，这才是真正的服务器开发。例如百度的后端，可能就设计搜索引擎组，
大数据组，数据挖掘，分布式文件系统，AI 等不同部门。所以学好后端的关键根本不是什么无聊的 web 框架，而是对于计算机的功力。

*** 大后端必须是分布式的
不知从 N 年前开始，互联网公司的内部业务，就必须是分布式的，不然不同部门间的不同业务怎么办？

****  通信
  既然大后端是分布式的，那么就涉及通信，且是重中之重，同时也是业务无关的。

  对于 c++ 来说，关注的就是 linux c/c++ 的 socket 编程。大学学的 Libevent, Thrift 等异步事件 socket 编程知识，之所以被业界称谓 "高性能服务器开发" 也是如此。

  以前不理解的：陈硕：Muduo 作为内部网络的分布式网络底层原来是这个意思。

***** RPC
   : 当下最流行的方式
    thrift workflow  muduo  grpc brpc 等都是这样，太多了。

**** 通信之上，分布式内部组件
: brpc在 百度的落地情况
: 公司名称： 百度
: 落地项目： 基础架构(分布式计算、存储、数据库等)，业务系统（Feed、凤巢、地图等）
***** 基础架构
****** Hadoop 等分布式存储基础架构（分布式文件系统 + 并行处理等等）
******* 分布式基础架构 Hadoop
- 从 brpc 的描述来看
  :  ELF(Essential/Extreme/Excellent Learning Framework) 框架为公司内外的大数据应用提供学习/挖掘算法开发支持。 平台主要包括数据迭代处理的框架支持，并行计算过程中的通信支持和用于存储大规模参数的分布式、快速、高可用参数服务器。应用于fcr-model，公有云bml，大数据实验室，语音技术部门等等。之前是基于[zeromq](http://zeromq.org/)封装的rpc，这次改用brpc。

  Hadoop 是属于大后端基础架构的一部分，你说学不学呢？

   建议好好学学 C++ 的分布式文件系统 bfs https://github.com/baidu/bfs
- 是存储吗？
- 还是计算？

******** Hadoop 架构学习
********* 架构图

hbase hive
mapreduce spark
    yarn
    HDFS

    最底层是分布式文件系统，Yarn 负责调度，Mapreduce 是并行计算，Spark 是更好的流式计算，可能直接在内存上计算。上层 hbase 是基于此构建的库，Hive 更是
    构建数据仓库，更是催生了大数据与数据挖掘的学科

********* 存储
底层是来自 HDFS, 分布式文件系统，让大量廉价的磁盘存储大量数据成为可能。

********* 计算
并行计算，可以同时计算不同的节点

******** 催生了大数据与数据挖掘
数据挖掘就是大数据学科非常重要的一环，毕竟大数据的一个用途就是挖掘出有关信息，例如电子商务中用于收集用户的喜好，不挖掘出有关信息，那么浪费那么多服务器干什么呢？
********* 大数据工程师负责数据采集
如果把 *数据挖掘工种* 从 *大数据工种* 中剥离，那么大数据工种则突出与 *数据采集*

把大量的数据采集到分布式基础架构上（Hadoop 为存储提供基础），特别是它的数据库上 为后续的数据挖掘提供基础

********* 数据挖掘
********** 定义
准确的说是叫做 KDD 知识挖掘，数据挖掘是其中的一环
********** 步骤
*********** 采集
上面，由大数据工种完成
*********** 数据预处理
 - 子步骤
   清洗，集成，数据转换，数据规约
 - 机器
   数据库，数据仓库
 - 系统实现
   通过清洗数据，通过集成导入数据仓库后，转换为特定数据集，就可以准备进行数据挖掘
*********** 数据挖掘
- 子步骤
  无
- 机器
  - 数据仓库
  - 数据挖掘引擎
  - 知识库
- 系统实现
  1. 数据仓库服务器负责根据用户的数据挖掘请求，读取相关数据。
  2. 知识库存放数据挖掘的领域知识，用于指导数据挖掘的分析过程，或者用于协助评估挖掘结果。
  3. 数据挖掘引擎包含一组挖掘功能模块，如关联分析、分类分析、聚类分析等。

*********** 后续处理
************ 模块评估与知识展示
可视化等等

***** 业务系统


* 优秀的 C 代码如何模块化设计
** 参考项目
+ 参考韦易笑推荐的大神的几个知名项目
  + tinyGL
  + libbpg
+ 以及之前都很中意同时也是非常流行的网络库（专业对口）
  + libevent
  + libev

** 总结
发现除了 libev 这种超级简单只有两个文件: ev.h ev.c （可能也是这个原因太简单了，没有必要做模块化）

其余的如何做模块化呢？

*** 给用户暴露最简单，最少的接口
  以纯函数作为接口，且只暴露最少的函数，以及少量的宏参数。尽量隐藏内部实现。

    + libevent
     在项目的 include 文件夹的编译后被 install, 被用户使用

      + 项目路径： ~/libevent/include/event2/listener.h
      + 用户使用：
        #include <event2/listener.h>

    + tinyGL
      同上，也是有一个 include 路径被用户编译后 install 后安装到 local

      + 项目路径： ~/tingl/include/GL/gl.h
      + 安装后被用户使用： #include <GL/gl.h>

    + libbpg
      是二进制程序，项目一共有 3 个二进制文件，
      都依赖于 libbpg.h

      + 我们主要关心如何把 *内部模块导出接口* 给二进制执行文件使用

        : 这是一个很厉害的设计，我以后设计 http 还要参考这招！！！

        内部的模块剥离出公共接口 libbpg.h 给最外面的三个 main.c 使用。

        + 注意，以下是猜测
          注意，这里和上面的面向用户的纯库不同，libevent 和 tinyGl 都是把 *面向用户的函数声明* 从内部移动到 include/xxoo.h 上。

          因此，内部实现模块 listen.c 还要 include <event2/listen.h> 。

          而这里，libbpg 是把内部实现好，压根就没有想过外部的接口，而临时糊一个 .h 出来作为接口。

          亦或许是任性，还是刚好接口全部实现都放在同一个文件里面！！！

        + 总之，就是接口还是隐藏了实现就对了

*** 内部模块化
首先要忘掉一切关于 oop 的概念，连类的封装都要忘掉！！！

也不要把文件当成一个单元，或者说一个文件代表一种数据结构（类），因为这都不是绝对的。

只有一个准则，就是说外部已经有接口的情况下，内部完全遵循自底向上，逐步迭代的思路。

甚至全部把 struct 写在一个 command 里面也是可以的。

* c 项目用的数据结构
: 收集一些，方便集成，同时自己也要多练，尽量保证可以自己写
** 顺序表
*** 侵入式的通用（泛型结构体，对象）表
+ 多功能顺序表，可用作队列，存储结构体对象，遍历等
  + 对于遍历来说
   把对象引用 / 指针存储在 vector 中，则具有 vector 一样的遍历效果

  + 对于插入删除来说
    能 O(1) 插入和删除，又能嵌入到红黑树里，方便遍历找到节点

+ 其不适合作为纯数据的缓存容器，但是构成上层的 page_stream 作为纯数据的缓存容器
**** list_head


*** 存储数据的缓存区
**** page_stream
***** Skywind3000/AsyncNet

**** Ringbuffer
***** Linux 内核的 kfifo

** 查找
*** 树
**** 红黑树
***** avlmini 里面的红黑树（其实也是取自 linux 内核红黑树）
**** avl 树
***** avlmini 里面的 avl 树
*** 查找哈希表
**** Linux 内核

*** 时间轮 O(1)
**** Skywind3000 AsyncNet

* Reactor
